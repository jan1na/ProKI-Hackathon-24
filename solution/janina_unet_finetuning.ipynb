{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 1: Install Required Libraries (run this in a separate cell)\n",
    "!pip install tensorflow segmentation-models albumentations\n",
    "\n",
    "# Step 2: Import Necessary Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive (for data storage)\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Step 3: Check Available Devices (GPU)\n",
    "print(\"Available devices:\")\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "# Set memory growth for GPU if available\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        for device in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(device, True)\n",
    "        print(f\"Using GPU: {physical_devices[0].name}\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Memory growth must be set at program startup. Exception:\", e)\n",
    "else:\n",
    "    print(\"No GPU found. Using CPU.\")\n",
    "\n",
    "# Step 4: Set Paths to Your Data (update these paths based on your Google Drive)\n",
    "IMAGE_PATH = '/content/drive/Meine Ablagen/ProKI-Hackathon/images/'\n",
    "MASK_PATH = '/content/drive/Meine Ablagen/ProKI-Hackathon/masks/'\n",
    "\n",
    "# Step 5: Load Data\n",
    "def load_data(image_path, mask_path):\n",
    "    images = []\n",
    "    masks = []\n",
    "    image_files = sorted(os.listdir(image_path))\n",
    "    mask_files = sorted(os.listdir(mask_path))\n",
    "\n",
    "    for img_file, mask_file in zip(image_files, mask_files):\n",
    "        img = tf.keras.utils.img_to_array(tf.keras.utils.load_img(os.path.join(image_path, img_file))) / 255.0  # Normalize images to [0, 1]\n",
    "        mask = (tf.keras.utils.img_to_array(tf.keras.utils.load_img(os.path.join(mask_path, mask_file), color_mode='grayscale')) > 0).astype(\n",
    "            np.float32)\n",
    "\n",
    "        images.append(img)\n",
    "        masks.append(mask)\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "# Step 6: Padding Function\n",
    "def pad_to_divisible(image, mask, divisor=32):\n",
    "    h, w = image.shape[:2]\n",
    "    new_h = (h + divisor - 1) // divisor * divisor\n",
    "    new_w = (w + divisor - 1) // divisor * divisor\n",
    "\n",
    "    # You can modify this padding size as needed; I am keeping it as 1024.\n",
    "    new_h = 1024\n",
    "    new_w = 1024\n",
    "\n",
    "    padded_image = np.zeros((new_h, new_w, 3), dtype=np.float32)\n",
    "    padded_image[:h, :w, :] = image\n",
    "\n",
    "    padded_mask = np.zeros((new_h, new_w), dtype=np.float32)\n",
    "    padded_mask[:h, :w] = mask.squeeze()\n",
    "\n",
    "    return padded_image, padded_mask\n",
    "\n",
    "# Step 7: Load and Pad the Dataset\n",
    "images, masks = load_data(IMAGE_PATH, MASK_PATH)\n",
    "padded_images, padded_masks = [], []\n",
    "\n",
    "for img, mask in zip(images, masks):\n",
    "    p_img, p_mask = pad_to_divisible(img, mask)\n",
    "    padded_images.append(p_img)\n",
    "    padded_masks.append(p_mask)\n",
    "\n",
    "padded_images = np.array(padded_images)\n",
    "padded_masks = np.array(padded_masks)\n",
    "\n",
    "# Step 8: Albumentations Data Augmentation\n",
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(),\n",
    "    A.Rotate(limit=45),\n",
    "    A.RandomBrightnessContrast(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Step 9: Pre-trained U-Net Model\n",
    "BACKBONE = 'resnet34'\n",
    "model = sm.Unet(\n",
    "    backbone_name=BACKBONE,\n",
    "    encoder_weights='imagenet',\n",
    "    classes=1,\n",
    "    activation='sigmoid',\n",
    "    input_shape=(None, None, 3)  # Allow dynamic sizes\n",
    ")\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 10: Callbacks\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_unet_model.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Step 11: Training\n",
    "history = model.fit(\n",
    "    padded_images,\n",
    "    padded_masks,\n",
    "    validation_split=0.2,\n",
    "    batch_size=16,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop, checkpoint]\n",
    ")\n",
    "\n",
    "# Step 12: Postprocessing: Crop Predicted Masks Back to Original Size\n",
    "def crop_to_original(padded_output, original_shape):\n",
    "    h, w = original_shape[:2]\n",
    "    return padded_output[:h, :w]\n",
    "\n",
    "# Step 13: Predict and Crop\n",
    "predicted_masks = model.predict(padded_images)\n",
    "original_masks = []\n",
    "\n",
    "for pred, original_img in zip(predicted_masks, images):\n",
    "    cropped_mask = crop_to_original(pred, original_img.shape)\n",
    "    original_masks.append(cropped_mask)\n",
    "\n",
    "original_masks = np.array(original_masks)\n",
    "\n",
    "# Step 14: Example Evaluation Metric: IoU\n",
    "def iou_score(y_true, y_pred):\n",
    "    intersection = np.sum(np.logical_and(y_true, y_pred))\n",
    "    union = np.sum(np.logical_or(y_true, y_pred))\n",
    "    return intersection / union\n",
    "\n",
    "# Step 15: Evaluate IoU on the Test Set\n",
    "test_iou = []\n",
    "for true_mask, pred_mask in zip(masks, original_masks):\n",
    "    test_iou.append(iou_score(true_mask > 0.5, pred_mask > 0.5))\n",
    "\n",
    "print(\"Average IoU on Test Set:\", np.mean(test_iou))\n",
    "\n",
    "model.save('/content/drive/MyDrive/saved_model')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a9a15cab32265b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
